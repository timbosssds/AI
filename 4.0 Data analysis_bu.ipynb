{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 02.12.24\n",
    "# Purpose: Question LLM, have it run code on my target file (csv)\n",
    "# Theme: Analyst\n",
    "# Status: 02.02.25 - demoed at work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 02.02.25\n",
    "# Note: Made a number of versions, but current at this time is Round 3. In Round 3 there are iterations\n",
    "# from being able to do Q&A on csv in notebook, to accessing that functionality via gradio UI, to the final, being all of the above (i.e. Q&A on CSV with UI), but this UI lets you upload the CSV.\n",
    "# Made a copy in Kaggle for work demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 1 <br>\n",
    "Drafting *(not sure completely working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key\n",
    "#!pip install python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "#load_dotenv()\n",
    "load_dotenv(dotenv_path='C:/Users/Tim_S/Desktop/bt/AI/local.env')\n",
    "\n",
    "# Now you can access the variables\n",
    "api = os.getenv('API_KEY')\n",
    "\n",
    "# Print them to confirm\n",
    "print(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not certain this is needed.\n",
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate i can call the llm\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='GOOGLE_API_KEY' )\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    ")\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "  ]\n",
    ")\n",
    "\n",
    "response = chat_session.send_message(\"Where is Paris\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the target data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('test.csv')\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LLM to analyse the data\n",
    "# Testing if model can be used for data analysis\n",
    "# Loan_ID\tGender\tMarried\tDependents\tEducation\tSelf_Employed\tApplicantIncome\tCoapplicantIncome\tLoanAmount\tLoan_Amount_Term\tCredit_History\tProperty_Area\n",
    "\n",
    "col = \"Loan_ID\",\"Gender\",\"Married\",\"Dependents\",\"Education\",\"Self_Employed\",\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\",\"Property_Area\"\n",
    "\n",
    "# -- Test model\n",
    "from IPython.display import Markdown, display\n",
    "# system = f\"\"\"You are an experienced data analayst, who specialises in analysing tabular data and responding to questions.\n",
    "#              The data set you will be analysing contains the following columns {col}\n",
    "#              Please generate python code to answer the question referencing the columns names provided.\n",
    "#              \"\"\"\n",
    " \n",
    "system = f\"\"\"You are an experienced data analayst who specialises writing python code to answer the questions.\n",
    "             The data set you will be analysing contains the following columns {col}\n",
    "             You are to respond with the python code (referencing the columns names provided) that would answer the question.\n",
    "             The code you provide is to be run a dataframe called df which already exists.\n",
    "             Please do not include any output other than the code.\n",
    "             The code will be surounded between these symbols # #\n",
    "             \"\"\"\n",
    "    \n",
    "\n",
    "user = \"Are there more men or woman in this data?\"\n",
    "#user = \"which education has the larges aggregate loan amount?\"\n",
    "#user = \"Are there more self employed men or woman in this data?\"\n",
    "\n",
    "#prompt = f\"System: {system} \\n User: {user} \\n AI: \"\n",
    "prompt = f\"System: {system} \\n User: {user} \\n AI: \"\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key= 'GOOGLE_API_KEY')\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    ")\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "  ]\n",
    ")\n",
    "\n",
    "response = chat_session.send_message(prompt)\n",
    "text = (response.text)\n",
    "print('this is the text.....', text)\n",
    "\n",
    "# ------------------------------------------------------- \n",
    "# Split the text into lines\n",
    "lines = text.strip().split('\\n')\n",
    "modified_lines = lines[1:-1]\n",
    "result = '\\n'.join(modified_lines)\n",
    "#print('target:', result)\n",
    "# ----- analyst output -----\n",
    "def remove_hash(result):\n",
    "    return result.replace('#', '').strip()\n",
    "b = remove_hash(result)\n",
    "#print('target2:', b)\n",
    "# ------------------------------------------------------- \n",
    "\n",
    "new_code = b\n",
    "generated_code = new_code\n",
    "ans = eval(generated_code)\n",
    "print(ans)\n",
    "\n",
    "\n",
    "# -- Testing if can add context to answer\n",
    "system = f\"\"\"You are a highly experienced analyst specialising responding to questions.\n",
    "             Your task is to combine the question {user} and answer {ans} into a helpful response.\n",
    "             \"\"\"\n",
    "prompt = f\"System: {system} \\n User: {user} \\n AI: \"\n",
    "    \n",
    "response = chat_session.send_message(prompt)\n",
    "text = (response.text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LLM to analyse the data\n",
    "# Testing if model can be used for data analysis\n",
    "# Loan_ID\tGender\tMarried\tDependents\tEducation\tSelf_Employed\tApplicantIncome\tCoapplicantIncome\tLoanAmount\tLoan_Amount_Term\tCredit_History\tProperty_Area\n",
    "\n",
    "col = \"Loan_ID\",\"Gender\",\"Married\",\"Dependents\",\"Education\",\"Self_Employed\",\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\",\"Property_Area\"\n",
    "\n",
    "# -- Test model\n",
    "from IPython.display import Markdown, display\n",
    "# system = f\"\"\"You are an experienced data analayst, who specialises in analysing tabular data and responding to questions.\n",
    "#              The data set you will be analysing contains the following columns {col}\n",
    "#              Please generate python code to answer the question referencing the columns names provided.\n",
    "#              \"\"\"\n",
    " \n",
    "\n",
    "user = \"Are there more men or woman in this data?\"\n",
    "#user = \"which education has the larges aggregate loan amount?\"\n",
    "#user = \"Are there more self employed men or woman in this data?\"\n",
    "\n",
    "system = f\"\"\"You are a highly experienced analayst, specialising in writing python code.\n",
    "            You are analysing a dataframe (df) with the following columns {col}\n",
    "            Your instructions are to\n",
    "            1. Create python code (that does not include functions) that would answer the following: {user}.\n",
    "            2. Ensure that the only output provided is the python code to answer {user}\n",
    "            \n",
    "            Before you provide the output make sure it meets all of the above criteria and instructions.\n",
    "            If it does not, then correct all issues before providing your reponse.\n",
    "            \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#prompt = f\"System: {system} \\n User: {user} \\n AI: \"\n",
    "#prompt = f\"System: {system} \\n User: {user}\"\n",
    "prompt = system\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='GOOGLE_API_KEY' )\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0.2,\n",
    "  \"top_p\": 0.5,\n",
    "  \"top_k\": 20,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    ")\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "  ]\n",
    ")\n",
    "\n",
    "response = chat_session.send_message(prompt)\n",
    "text = (response.text)\n",
    "print(text)\n",
    "\n",
    "# # ------------------------------------------------------- \n",
    "# # Split the text into lines\n",
    "# lines = text.strip().split('\\n')\n",
    "# modified_lines = lines[1:-1]\n",
    "# result = '\\n'.join(modified_lines)\n",
    "# #print('target:', result)\n",
    "# # ----- analyst output -----\n",
    "# def remove_hash(result):\n",
    "#     return result.replace('#', '').strip()\n",
    "# b = remove_hash(result)\n",
    "# #print('target2:', b)\n",
    "# # ------------------------------------------------------- \n",
    "\n",
    "# new_code = b\n",
    "# generated_code = new_code\n",
    "# ans = eval(generated_code)\n",
    "# print(ans)\n",
    "\n",
    "\n",
    "# # -- Testing if can add context to answer\n",
    "# system = f\"\"\"You are a highly experienced analyst specialising responding to questions.\n",
    "#              Your task is to combine the question {user} and answer {ans} into a helpful response.\n",
    "#              \"\"\"\n",
    "# prompt = f\"System: {system} \\n User: {user} \\n AI: \"\n",
    "    \n",
    "# response = chat_session.send_message(prompt)\n",
    "# text = (response.text)\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per above, but new question.\n",
    "\n",
    "# Testing if model can be used for data analysis\n",
    "# Loan_ID\tGender\tMarried\tDependents\tEducation\tSelf_Employed\tApplicantIncome\tCoapplicantIncome\tLoanAmount\tLoan_Amount_Term\tCredit_History\tProperty_Area\n",
    "\n",
    "col = \"Loan_ID\",\"Gender\",\"Married\",\"Dependents\",\"Education\",\"Self_Employed\",\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\",\"Property_Area\"\n",
    "\n",
    "# -- Test model\n",
    "from IPython.display import Markdown, display\n",
    "# system = f\"\"\"You are an experienced data analayst, who specialises in analysing tabular data and responding to questions.\n",
    "#              The data set you will be analysing contains the following columns {col}\n",
    "#              Please generate python code to answer the question referencing the columns names provided.\n",
    "#              \"\"\"\n",
    " \n",
    "system = f\"\"\"You are a highly experienced analyst specialising in writing python code.\n",
    "             You will provide the required python code to answer any questions you are asked\n",
    "             The data set you will be analysing contains the following columns {col}\n",
    "             The code you provide is to be run a dataframe called df which already exists.\n",
    "             Please do not include any output other than the code.\n",
    "             The code will be surounded between these symbols # #\n",
    "             \"\"\"\n",
    "    \n",
    "#user = \"What is the capital of Spain\"\n",
    "user = \"Are there more men or woman in this data?\"\n",
    "#user = \"Are there more self employed men or woman in this data?\"\n",
    "#user = \"which education has the larges aggregate loan amount?\"\n",
    "#user = \"Which Property areas has the has the largest combined loan amount?\"\n",
    "#user = \"What is the eligibility of the Easy Money Card?\"\n",
    "prompt = system + user\n",
    "    \n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='GOOGLE_API_KEY' )\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    ")\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "  ]\n",
    ")\n",
    "\n",
    "response = chat_session.send_message(prompt)\n",
    "text = (response.text)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# # ----- analyst output -----\n",
    "def remove_hash(text):\n",
    "    return text.replace('#', '').strip()\n",
    "b = remove_hash(text)\n",
    "new_code = b\n",
    "generated_code = new_code\n",
    "ans = eval(generated_code)\n",
    "\n",
    "\n",
    "# -- Testing if can add context to answer\n",
    "system = f\"\"\"You are a highly experienced analyst specialising responding to questions.\n",
    "             Your task is to combine the question {user} and answer {ans} into a helpful response.\n",
    "             \"\"\"\n",
    "prompt = f\"System: {system} \\n User: {user} \\n AI: \"\n",
    "    \n",
    "response = chat_session.send_message(prompt)\n",
    "text = (response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "\n",
    "# Configure the Generative AI model with your API key\n",
    "genai.configure(api_key='GOOGLE_API_KEY')\n",
    "\n",
    "# Create the model with specified configuration\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "# Start a chat session with the model\n",
    "chat_session = model.start_chat(\n",
    "    history=[]\n",
    ")\n",
    "\n",
    "# Function to create and run Python code based on DataFrame column names\n",
    "def generate_and_run_code(column_names, question):\n",
    "    # Create a prompt for generating Python code\n",
    "    prompt = f\"Given the DataFrame with columns {column_names}, write Python code to answer the question: {question}\"\n",
    "    \n",
    "    # Send the prompt to the AI model and get the generated code\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    \n",
    "    # Print the generated code for review\n",
    "    print(\"Generated Code:\\n\", generated_code)\n",
    "    \n",
    "    # Execute the generated code using exec()\n",
    "    try:\n",
    "        exec(generated_code)\n",
    "    except Exception as e:\n",
    "        print(\"Error executing generated code:\", e)\n",
    "\n",
    "# Example usage\n",
    "column_names = ['Name', 'Team', 'Number']  # Replace with actual column names from your DataFrame\n",
    "question = \"What is the average Number for each Team?\"  # Replace with your specific question\n",
    "\n",
    "generate_and_run_code(column_names, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 2 <br>\n",
    "Working well till asked a question that need a function to answer (so creating 3 to see if functions can be used every time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a: Works (without function - do not edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the target data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('test.csv')\n",
    "display(df.head(2))\n",
    "column_names = df.columns.to_list()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# ----- Part 1.0: the llm ----------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "\n",
    "# Configure the Generative AI model with your API key\n",
    "genai.configure(api_key='GOOGLE_API_KEY')\n",
    "\n",
    "# Create the model with specified configuration\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 20,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "# Start a chat session with the model\n",
    "chat_session = model.start_chat(\n",
    "    history=[]\n",
    ")\n",
    "\n",
    "# Function to create and run Python code based on DataFrame column names\n",
    "def generate_and_run_code(column_names, question):\n",
    "    # Create a prompt for generating Python code\n",
    "    #print(column_names)\n",
    "    prompt = f\"\"\"You are an experienced data analayst who specialises writing python code to answer the questions.\n",
    "             The data set you will be analysing contains the following columns {column_names}\n",
    "             You are to respond with the python code that would answer the question {question}.\n",
    "             The code you provide is to be run a dataframe called df which already exists.\n",
    "\n",
    "             The quality of your answer will be judged by the following criteria;\n",
    "             - Your code output will run succesfully with the python eval function\n",
    "             - Your code will run in a single step, it will not create a variable that then needs printing\n",
    "             - Your output will be python code that can be run by another system immediatedly without error or adjustment\n",
    "             - You will NOT provide any theory or suggestions on how to answer the question\n",
    "             - If your output can not be passed straight to another system and run without error then that is a failure on your part\n",
    "             - You do NOT need to provide comments in your code.\n",
    "             - Your code will be as simple as possible to answer the question but not simpler\n",
    "             The code will be surounded between these symbols \n",
    "             # \n",
    "             \\n 'code'\n",
    "             #\n",
    "             \"\"\"\n",
    "    \n",
    "    # Send the prompt to the AI model and get the generated code\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    \n",
    "    a = generated_code\n",
    "    # -- Print the generated code for review (or return if testing)\n",
    "    #print(\"Generated Code:\\n\", generated_code)\n",
    "    return(generated_code)\n",
    "\n",
    "\n",
    "column_names = column_names  # Replace with actual column names from your DataFrame\n",
    "#question = \"Are there more men or women in this data & can you provide counts of both gender?\"  # Replace with your specific question\n",
    "#question = \"which education has the larges aggregate loan amount?\"\n",
    "question = \"Can you show me the breakdown of education per gender?\"\n",
    "#question = \"Can you show me the top 5 most profitable customers based on loan amount?\"\n",
    "#question = \"Based on applicant income and loan amount, can you please show me the 5 customers at risk of default if there were an interest rate increase?\"\n",
    "#question = \"Can you show me the top 3 customers with the highest combined income (i.e. applicant and coapplicant income)?\"\n",
    "c = generate_and_run_code(column_names, question)\n",
    "#print(c)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.0: the clean up -----------------------------------\n",
    "# --------------------------------------------------------------\n",
    "# -- This is the functtion to clean up\n",
    "# import ast\n",
    "import re\n",
    "\n",
    "def extract_python_code(code_str):\n",
    "    # Remove the markdown code block markers (```)\n",
    "    code_str = re.sub(r'```python|```', '', code_str)\n",
    "\n",
    "    # Remove comments from the string\n",
    "    code_str = re.sub(r'#.*', '', code_str)\n",
    "\n",
    "    # Attempt to parse the remaining code to ensure it's valid Python\n",
    "    try:\n",
    "        # Use the ast.parse function to check if the code is valid Python syntax\n",
    "        ast.parse(code_str)\n",
    "        return code_str.strip()  # Return the code if it's valid\n",
    "    except SyntaxError:\n",
    "        return \"\"  # Return an empty string if the code is invalid\n",
    "    \n",
    "#print(extract_python_code(c))  \n",
    "d = extract_python_code(c)\n",
    "#print(d)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.1: validate code before running------------------\n",
    "# --------------------------------------------------------------\n",
    "def valcode(code):\n",
    "    # Create a prompt for generating Python code\n",
    "    #print(column_names)\n",
    "    prompt = f\"\"\"Can you verify if this code would be safe to ru or does it contain potential security related issues. \n",
    "                 Can you respond with one of the below\n",
    "                 - safe (as in no hidden threats or issues), \n",
    "                 - investigate (as in contains potentially suspicious code, not needed to be run to achieve the expected result), \n",
    "                 - threat (as in contains malicious intent in code base):ode'\n",
    "             #\n",
    "             \"\"\"\n",
    "    \n",
    "    # Send the prompt to the AI model and get the generated code\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    \n",
    "    a = generated_code\n",
    "    return(generated_code)\n",
    "\n",
    "code = d\n",
    "f = valcode(code)\n",
    "#print(f)\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 3.0: execution ------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "print('\\n')\n",
    "print('-'*15, 'the answer', '-'*15)\n",
    "#eval(d)\n",
    "\n",
    "# modifying to now work with the safety feature\n",
    "if \"safe\" in f:\n",
    "    #print('all good')\n",
    "    display(eval(d))\n",
    "else:\n",
    "    print('chill bruv')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Breaking it down to stages (used to build out above)\n",
    "There may have been changes made in the above code, so while the below is for breaking down and experimenting with code, DO NOT come back to this a copy chunks of below to replace chunks for above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .... Making it work once step at a time...\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "\n",
    "# Configure the Generative AI model with your API key\n",
    "genai.configure(api_key='GOOGLE_API_KEY')\n",
    "\n",
    "# Create the model with specified configuration\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 20,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "# Start a chat session with the model\n",
    "chat_session = model.start_chat(\n",
    "    history=[]\n",
    ")\n",
    "\n",
    "# Function to create and run Python code based on DataFrame column names\n",
    "def generate_and_run_code(column_names, question):\n",
    "    # Create a prompt for generating Python code\n",
    "    #print(column_names)\n",
    "    prompt = f\"\"\"You are an experienced data analayst who specialises writing python code to answer the questions.\n",
    "             The data set you will be analysing contains the following columns {column_names}\n",
    "             You are to respond with the python code that would answer the question {question}.\n",
    "             The code you provide is to be run a dataframe called df which already exists.\n",
    "\n",
    "             The quality of your answer will be judged by the following criteria;\n",
    "             - Your code output will run succesfully with the python eval function\n",
    "             - Your code will run in a single step, it will not create a variable that then needs printing\n",
    "             - Your output will be python code that can be run by another system immediatedly without error or adjustment\n",
    "             - You will NOT provide any theory or suggestions on how to answer the question\n",
    "             - If your output can not be passed straight to another system and run without error then that is a failure on your part\n",
    "             - You do NOT need to provide comments in your code.\n",
    "             - Your code will be as simple as possible to answer the question but not simpler\n",
    "             - You will output your code as a function AND the call action that function i.e.\n",
    "               def cde(df):\n",
    "                   out = >insert created code here<\n",
    "                   print out\n",
    "                print(cde(df))   \n",
    "             The code will be surounded between these symbols \n",
    "             # \n",
    "             \\n 'code'\n",
    "             #\n",
    "             \"\"\"\n",
    "    \n",
    "    # Send the prompt to the AI model and get the generated code\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    \n",
    "    a = generated_code\n",
    "    # -- Print the generated code for review (or return if testing)\n",
    "    print(\"Generated Code:\\n\", generated_code)\n",
    "    return(generated_code)\n",
    "\n",
    "\n",
    "column_names = column_names  # Replace with actual column names from your DataFrame\n",
    "question = \"Are there more men or women in this data & can you provide counts of both gender?\"  # Replace with your specific question\n",
    "#question = \"which education has the larges aggregate loan amount?\"\n",
    "#question = \"Can you show me the top 3 customers with the highest combined income (i.e. applicant and coapplicant income)?\"\n",
    "c = generate_and_run_code(column_names, question)\n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- This is the functtion to clean up\n",
    "# import ast\n",
    "import re\n",
    "\n",
    "def extract_python_code(code_str):\n",
    "    # Remove the markdown code block markers (```)\n",
    "    code_str = re.sub(r'```python|```', '', code_str)\n",
    "\n",
    "    # Remove comments from the string\n",
    "    code_str = re.sub(r'#.*', '', code_str)\n",
    "\n",
    "    # Attempt to parse the remaining code to ensure it's valid Python\n",
    "    try:\n",
    "        # Use the ast.parse function to check if the code is valid Python syntax\n",
    "        ast.parse(code_str)\n",
    "        return code_str.strip()  # Return the code if it's valid\n",
    "    except SyntaxError:\n",
    "        return \"\"  # Return an empty string if the code is invalid\n",
    "    \n",
    "print(extract_python_code(c))  \n",
    "d = extract_python_code(c)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trialling a new step (to verify that generated code is safe)\n",
    "\n",
    "# Function to create and run Python code based on DataFrame column names\n",
    "def valcode(code):\n",
    "    # Create a prompt for generating Python code\n",
    "    #print(column_names)\n",
    "    prompt = f\"\"\"Can you verify if this code would be safe to ru or does it contain potential security related issues. \n",
    "                 Can you respond with one of the below\n",
    "                 - safe (as in no hidden threats or issues), \n",
    "                 - investigate (as in contains potentially suspicious code, not needed to be run to achieve the expected result), \n",
    "                 - threat (as in contains malicious intent in code base):ode'\n",
    "             #\n",
    "             \"\"\"\n",
    "    \n",
    "    # Send the prompt to the AI model and get the generated code\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    \n",
    "    a = generated_code\n",
    "    # -- Print the generated code for review (or return if testing)\n",
    "    #print(\"Generated Code:\\n\", generated_code)\n",
    "    return(generated_code)\n",
    "\n",
    "code = d\n",
    "f = valcode(code)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# # Example usage\n",
    "#eval(d)\n",
    "\n",
    "# modifying to now work with the safety feature\n",
    "if \"safe\" in f:\n",
    "    #print('all good')\n",
    "    exec(d)\n",
    "else:\n",
    "    print('chill bruv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 (Fixing parts of part 2 as required) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest question is creating a new col in the dataframe, this is no good.\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 1.0: the llm ----------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "\n",
    "# Configure the Generative AI model with your API key\n",
    "genai.configure(api_key='GOOGLE_API_KEY')\n",
    "\n",
    "# Create the model with specified configuration\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 20,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "# Start a chat session with the model\n",
    "chat_session = model.start_chat(\n",
    "    history=[]\n",
    ")\n",
    "\n",
    "# Function to create and run Python code based on DataFrame column names\n",
    "def generate_and_run_code(column_names, question):\n",
    "    # Create a prompt for generating Python code\n",
    "    #print(column_names)\n",
    "    prompt = f\"\"\"You are an experienced data analayst who specialises writing python code to answer the questions.\n",
    "             The data set you will be analysing contains the following columns {column_names}\n",
    "             You are to respond with the python code that would answer the question {question}.\n",
    "             The code you provide is to be run a dataframe called df which already exists.\n",
    "\n",
    "             The quality of your answer will be judged by the following criteria;\n",
    "             - Your code output will run succesfully with the python eval function\n",
    "             - Your code will run in a single step, it will not create a variable that then needs printing\n",
    "             - Your output will be python code that can be run by another system immediatedly without error or adjustment\n",
    "             - You will NOT provide any theory or suggestions on how to answer the question\n",
    "             - If your output can not be passed straight to another system and run without error then that is a failure on your part\n",
    "             - You do NOT need to provide comments in your code.\n",
    "             - Your code will be as simple as possible to answer the question but not simpler\n",
    "             - You will output your code as a function AND the call action that function i.e.\n",
    "               def cde(df):\n",
    "                   out = >insert created code here<\n",
    "                   print out\n",
    "                print(cde(df))   \n",
    "             The code will be surounded between these symbols \n",
    "             # \n",
    "             \\n 'code'\n",
    "             #\n",
    "             \"\"\"\n",
    "    \n",
    "    # Send the prompt to the AI model and get the generated code\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    \n",
    "    a = generated_code\n",
    "    # -- Print the generated code for review (or return if testing)\n",
    "    #print(\"Generated Code:\\n\", generated_code)\n",
    "    return(generated_code)\n",
    "\n",
    "\n",
    "column_names = column_names  # Replace with actual column names from your DataFrame\n",
    "#question = \"Are there more men or women in this data & can you provide counts of both gender?\"  # Replace with your specific question\n",
    "#question = \"which education has the larges aggregate loan amount?\"\n",
    "question = \"Can you show me the breakdown of education per gender?\"\n",
    "#question = \"Can you show me the top 5 most profitable customers based on loan amount?\"\n",
    "#question = \"Based on applicant income and loan amount, can you please show me the 5 customers at risk of default if there were an interest rate increase?\"\n",
    "#question = \"Can you show me the top 3 customers with the highest combined income (i.e. applicant and coapplicant income)?\"\n",
    "c = generate_and_run_code(column_names, question)\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- This is the functtion to clean up\n",
    "# import ast\n",
    "import re\n",
    "\n",
    "def extract_python_code(code_str):\n",
    "    # Remove the markdown code block markers (```)\n",
    "    code_str = re.sub(r'```python|```', '', code_str)\n",
    "\n",
    "    # Remove comments from the string\n",
    "    code_str = re.sub(r'#.*', '', code_str)\n",
    "\n",
    "    # Attempt to parse the remaining code to ensure it's valid Python\n",
    "    try:\n",
    "        # Use the ast.parse function to check if the code is valid Python syntax\n",
    "        ast.parse(code_str)\n",
    "        return code_str.strip()  # Return the code if it's valid\n",
    "    except SyntaxError:\n",
    "        return \"\"  # Return an empty string if the code is invalid\n",
    "    \n",
    "print(extract_python_code(c))  \n",
    "d = extract_python_code(c)\n",
    "print(d)\n",
    "\n",
    "print(exec(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "def cde(df1):\n",
    "    out = df1['Gender'].value_counts()\n",
    "    return out\n",
    "display(cde(df1))\n",
    "\n",
    "print(d)\n",
    "\n",
    "print(exec(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 3 <br>\n",
    "As per Round 2, but looking to use function for every response (so if function ever needed, it will support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Draft (Working, with no UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim_S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def cde(df):\n",
      "    out = df.groupby('Pclass')['Survived'].mean().idxmax()\n",
      "    return out\n",
      "safe\n",
      "\n",
      "\n",
      "--------------- the answer ---------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 153\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchill bruv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# ----- Part 3.0: agent ----------------------------------------\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mYou are a super helpful agent who responds to enquires.\u001b[39;49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;43m                                     You have been provided with a question \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquestion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m and answer \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresult\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;43m                                     Your task is to use the answer to respond to the question in an informative & helpful way\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\generativeai\\generative_models.py:578\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[1;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid configuration: The chat functionality does not support `candidate_count` greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m     )\n\u001b[1;32m--> 578\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(response\u001b[38;5;241m=\u001b[39mresponse, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_automatic_function_calling \u001b[38;5;129;01mand\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\grpc\\_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1168\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1175\u001b[0m     (\n\u001b[0;32m   1176\u001b[0m         state,\n\u001b[0;32m   1177\u001b[0m         call,\n\u001b[1;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\grpc\\_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[0;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[0;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the target data\n",
    "import pandas as pd\n",
    "#df = pd.read_csv('test.csv')\n",
    "df = pd.read_csv('Titanic_train.csv')\n",
    "#display(df.head(2))\n",
    "column_names = df.columns.to_list()\n",
    "print(column_names)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 1.0: the llm ----------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "# Create the model with specified configuration\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 20,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,)\n",
    "chat_session = model.start_chat(\n",
    "    history=[]\n",
    ")\n",
    "\n",
    "def generate_and_run_code(column_names, question):\n",
    "    #print(column_names)\n",
    "    prompt = f\"\"\"You are an experienced data analayst who specialises writing python code to answer the questions.\n",
    "             The data set you will be analysing contains the following columns {column_names}\n",
    "             You are to respond with the python code that would answer the question {question}.\n",
    "             The code you provide is to be run a dataframe called df which already exists.\n",
    "\n",
    "             The quality of your answer will be judged by the following criteria;\n",
    "             - Your code output will run succesfully with the python eval function\n",
    "             - Your code will run in a single step, it will not create a variable that then needs printing\n",
    "             - Your output will be python code that can be run by another system immediatedly without error or adjustment\n",
    "             - You will NOT provide any theory or suggestions on how to answer the question\n",
    "             - If your output can not be passed straight to another system and run without error then that is a failure on your part\n",
    "             - You do NOT need to provide comments in your code.\n",
    "             - Your code will be as simple as possible to answer the question but not simpler\n",
    "             - You will output your code as a function i.e.\n",
    "               def cde(df):\n",
    "                   out = >insert created code here<\n",
    "                   return out\n",
    "                The code will be surounded between these symbols \n",
    "             # \n",
    "             \\n 'code'\n",
    "             #\n",
    "             \"\"\"\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    \n",
    "    a = generated_code\n",
    "    #print(\"Generated Code:\\n\", generated_code)\n",
    "    return(generated_code)\n",
    "\n",
    "\n",
    "column_names = column_names  # Replace with actual column names from your DataFrame\n",
    "#question = \"Are there more men or women in this data & can you provide counts of both gender?\"  # Replace with your specific question\n",
    "#question = \"which education has the larges aggregate loan amount?\"\n",
    "#question = \"Can you show me the top 3 customers with the highest combined income (i.e. applicant and coapplicant income)?\"\n",
    "#question = \"which education has the larges aggregate loan amount?\"\n",
    "#question = \"Can you show me the breakdown of education per gender?\"\n",
    "#question = \"Can you show me the top 5 most profitable customers based on loan amount?\"\n",
    "#question = \"Based on applicant income and loan amount, can you please show me the 5 customers at risk of default if there were an interest rate increase?\"\n",
    "#question = \"Can you show me the top 3 customers with the highest combined income (i.e. applicant and coapplicant income)?\"\n",
    "question = \"looking at Pclass and Survived, can you tell me which pclass had the highest survival rate (where 0 equals perished and 1 means survived)?\"\n",
    "c = generate_and_run_code(column_names, question)\n",
    "#print(c)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.0: the clean up -----------------------------------\n",
    "# --------------------------------------------------------------\n",
    "# -- This is the functtion to clean up\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def extract_python_code(code_str):\n",
    "    # Remove the markdown code block markers (```)\n",
    "    code_str = re.sub(r'```python|```', '', code_str)\n",
    "    # Remove comments from the string\n",
    "    code_str = re.sub(r'#.*', '', code_str)\n",
    "\n",
    "    # Attempt to parse the remaining code to ensure it's valid Python\n",
    "    try:\n",
    "        # Use the ast.parse function to check if the code is valid Python syntax\n",
    "        ast.parse(code_str)\n",
    "        return code_str.strip()  # Return the code if it's valid\n",
    "    except SyntaxError:\n",
    "        return \"\"  # Return an empty string if the code is invalid\n",
    "print(extract_python_code(c))  \n",
    "d = extract_python_code(c)\n",
    "#print(d)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.1: validate code before running------------------\n",
    "# --------------------------------------------------------------\n",
    "# Function to create and run Python code based on DataFrame column names\n",
    "def valcode(code):\n",
    "    # Create a prompt for generating Python code\n",
    "    #print(column_names)\n",
    "    prompt = f\"\"\"Can you verify if this code would be safe to ru or does it contain potential security related issues. \n",
    "                 Can you respond with one of the below\n",
    "                 - safe (as in no hidden threats or issues), \n",
    "                 - investigate (as in contains potentially suspicious code, not needed to be run to achieve the expected result), \n",
    "                 - threat (as in contains malicious intent in code basee'\n",
    "             #\n",
    "             \"\"\"\n",
    "    \n",
    "    # Send the prompt to the AI model and get the generated code\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    \n",
    "    a = generated_code\n",
    "    #print(\"Generated Code:\\n\", generated_code)\n",
    "    return(generated_code)\n",
    "code = d\n",
    "f = valcode(code)\n",
    "print(f)\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 3.0: execution ------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "print('\\n')\n",
    "print('-'*15, 'the answer', '-'*15)\n",
    "# modifying to now work with the safety feature\n",
    "if \"safe\" in f:\n",
    "    # This is the function as a string (generated by the LLM)\n",
    "    function_string = d\n",
    "    # Execute the function string to define it in the current scope\n",
    "    exec(function_string)\n",
    "    # Now, you can call the function as if it were defined normally\n",
    "    result = cde(df)\n",
    "    #print(result)\n",
    "else:\n",
    "    print('chill bruv')  \n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 3.0: agent ----------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "response = chat_session.send_message(f\"\"\"You are a super helpful agent who responds to enquires.\n",
    "                                     You have been provided with a question {question} and answer {result}.\n",
    "                                     Your task is to use the answer to respond to the question in an informative & helpful way\"\"\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- The logic that solved the code execution peice\n",
    "# This is the function as a string (generated by the LLM)\n",
    "function_string = \"\"\"\n",
    "def my_function11(x, y):\n",
    "    return x + y\n",
    "\"\"\"\n",
    "# Execute the function string to define it in the current scope\n",
    "exec(function_string)\n",
    "# Now, you can call the function as if it were defined normally\n",
    "result = my_function11(5, 3)\n",
    "print(result)  # Output: 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Draft 1.0 (Working, with basic ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using chat to take above, make changes as required and add gradio...\n",
    "#!pip  install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Milestone - do not edit\n",
    "# -- UI, with functional backend.\n",
    "# -- Will see if i can add a csv upload feature\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import ast\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "column_names = df.columns.to_list()\n",
    "\n",
    "# Configure the Generative AI model\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 20,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "chat_session = model.start_chat(history=[])\n",
    "\n",
    "def generate_and_run_code(question):\n",
    "    prompt = f\"\"\"You are an experienced data analayst who specialises writing python code to answer the questions.\n",
    "            The data set you will be analysing contains the following columns {column_names}\n",
    "            You are to respond with the python code that would answer the question {question}.\n",
    "            The code you provide is to be run a dataframe called df which already exists.\n",
    "\n",
    "            The quality of your answer will be judged by the following criteria;\n",
    "            - Your code output will run succesfully with the python eval function\n",
    "            - Your code will run in a single step, it will not create a variable that then needs printing\n",
    "            - Your output will be python code that can be run by another system immediatedly without error or adjustment\n",
    "            - You will NOT provide any theory or suggestions on how to answer the question\n",
    "            - If your output can not be passed straight to another system and run without error then that is a failure on your part\n",
    "            - You do NOT need to provide comments in your code.\n",
    "            - Your code will be as simple as possible to answer the question but not simpler\n",
    "            - You will output your code as a function i.e.\n",
    "            def cde(df):\n",
    "                out = >insert created code here<\n",
    "                return out\n",
    "            The code will be surounded between these symbols \n",
    "            # \n",
    "            \\n 'code'\n",
    "            #\n",
    "            \"\"\"\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    return extract_python_code(generated_code)\n",
    "\n",
    "def extract_python_code(code_str):\n",
    "    code_str = re.sub(r'```python|```', '', code_str)\n",
    "    code_str = re.sub(r'#.*', '', code_str)\n",
    "    try:\n",
    "        ast.parse(code_str)\n",
    "        return code_str.strip()\n",
    "    except SyntaxError:\n",
    "        return \"\"\n",
    "\n",
    "def valcode(code):\n",
    "    prompt = f\"\"\"Can you verify if this code is safe to run? Respond with:\n",
    "                 - safe\n",
    "                 - investigate\n",
    "                 - threat\"\"\"\n",
    "    response = chat_session.send_message(prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "def execute_code(question):\n",
    "    generated_code = generate_and_run_code(question)\n",
    "    if not generated_code:\n",
    "        return \"Failed to generate valid code.\"\n",
    "    \n",
    "    safety_check = valcode(generated_code)\n",
    "    if \"safe\" not in safety_check:\n",
    "        return \"Code is flagged as unsafe. Execution halted.\"\n",
    "    \n",
    "    exec(generated_code, globals())\n",
    "    if 'cde' in globals():\n",
    "        result = cde(df)\n",
    "        #response = chat_session.send_message(f\"Question: {question}\\nAnswer: {result}\")\n",
    "\n",
    "        response = chat_session.send_message(f\"\"\"You are a super helpful agent who responds to enquires.\n",
    "                                     You have been provided with a question {question} and answer {result}.\n",
    "                                     Your task is to use the answer to respond to the question in an informative & helpful way\"\"\")\n",
    "\n",
    "        return response.text\n",
    "    else:\n",
    "        return \"Generated code did not define a function properly.\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=execute_code,\n",
    "    inputs=gr.Textbox(label=\"Enter your question\"),\n",
    "    outputs=gr.Textbox(label=\"Answer\"),\n",
    "    title=\"AI Data Analysis Assistant\",\n",
    "    description=\"Ask a question related to the dataset, and the AI will generate, validate, and execute the necessary code.\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Draft 2.0 (Working, with UI & file upload (via ui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import ast\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def load_csv(file):\n",
    "    df = pd.read_csv(file.name)\n",
    "    return df, df.columns.to_list()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 1.0: the llm --------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 20,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "chat_session = model.start_chat(history=[])\n",
    "\n",
    "def generate_and_run_code(df, question):\n",
    "    column_names = df.columns.to_list()\n",
    "    prompt = f\"\"\"You are an experienced data analayst who specialises writing python code to answer the questions.\n",
    "            The data set you will be analysing contains the following columns {column_names}\n",
    "            You are to respond with the python code that would answer the question {question}.\n",
    "            The code you provide is to be run a dataframe called df which already exists.\n",
    "\n",
    "            The quality of your answer will be judged by the following criteria;\n",
    "            - Your code output will run succesfully with the python eval function\n",
    "            - Your code will run in a single step, it will not create a variable that then needs printing\n",
    "            - Your output will be python code that can be run by another system immediatedly without error or adjustment\n",
    "            - You will NOT provide any theory or suggestions on how to answer the question\n",
    "            - If your output can not be passed straight to another system and run without error then that is a failure on your part\n",
    "            - You do NOT need to provide comments in your code.\n",
    "            - Your code will be as simple as possible to answer the question but not simpler\n",
    "            - You will output your code as a function i.e.\n",
    "            def cde(df):\n",
    "                out = >insert created code here<\n",
    "                return out\n",
    "            The code will be surounded between these symbols \n",
    "            # \n",
    "            \\n 'code'\n",
    "            #\n",
    "            \"\"\"\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    return extract_python_code(generated_code)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.0: the clean up ---------------------------------\n",
    "# --------------------------------------------------------------\n",
    "def extract_python_code(code_str):\n",
    "    code_str = re.sub(r'```python|```', '', code_str)\n",
    "    code_str = re.sub(r'#.*', '', code_str)\n",
    "    try:\n",
    "        ast.parse(code_str)\n",
    "        return code_str.strip()\n",
    "    except SyntaxError:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.1: validate code before running------------------\n",
    "# --------------------------------------------------------------    \n",
    "def valcode(code):\n",
    "    prompt = f\"\"\"Can you verify if this code is safe to run? Respond with:\n",
    "                 - safe\n",
    "                 - investigate\n",
    "                 - threat\"\"\"\n",
    "    response = chat_session.send_message(prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 3.0: execution ------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "def execute_code(csv_file, question):\n",
    "    df, column_names = load_csv(csv_file)\n",
    "    generated_code = generate_and_run_code(df, question)\n",
    "    if not generated_code:\n",
    "        return \"Failed to generate valid code.\"\n",
    "    \n",
    "    safety_check = valcode(generated_code)\n",
    "    if \"safe\" not in safety_check:\n",
    "        return \"Code is flagged as unsafe. Execution halted.\"\n",
    "    \n",
    "    exec(generated_code, globals())\n",
    "    if 'cde' in globals():\n",
    "        result = cde(df)\n",
    "        #response = chat_session.send_message(f\"Question: {question}\\nAnswer: {result}\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 4.0: agent ----------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "        response = chat_session.send_message(f\"\"\"You are a super helpful agent who responds to enquires.\n",
    "                                     You have been provided with a question {question} and answer {result}.\n",
    "                                     Your task is to use the answer to respond to the question in an informative & helpful way\"\"\")\n",
    "        return response.text\n",
    "    else:\n",
    "        return \"Generated code did not define a function properly.\"\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 5.0: ui -------------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "demo = gr.Interface(\n",
    "    fn=execute_code,\n",
    "    inputs=[gr.File(label=\"Upload CSV File\"), gr.Textbox(label=\"Enter your question\")],\n",
    "    outputs=gr.Textbox(label=\"Answer\"),\n",
    "    title=\"AI Data Analysis Assistant\",\n",
    "    description=\"Upload a CSV file and ask a question related to the dataset. The AI will generate, validate, and execute the necessary code.\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = column_names  # Replace with actual column names from your DataFrame\n",
    "#question = \"Are there more men or women in this data & can you provide counts of both gender?\"  # Replace with your specific question\n",
    "question = \"which education has the largest aggregate loan amount?\"\n",
    "#question = \"Can you show me the top 3 customers with the highest combined income (i.e. applicant and coapplicant income)?\"\n",
    "#question = \"which education has the larges aggregate loan amount?\"\n",
    "#question = \"Can you show me the breakdown of education per gender?\"\n",
    "#question = \"Can you show me the top 5 most profitable customers based on loan amount?\"\n",
    "#question = \"Based on applicant income and loan amount, can you please show me the 5 customers at risk of default if there were an interest rate increase?\"\n",
    "#question = \"Can you show me the top 3 customers with the highest combined income (i.e. applicant and coapplicant income)?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_csv(file):\n",
    "    df = pd.read_csv('test.csv')\n",
    "    return df, df.columns.to_list()\n",
    "\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "def execute_code(csv_file, question):\n",
    "    dfa, column_namesa = load_csv(csv_file)\n",
    "    print (dfa.head(2))\n",
    "    print (column_namesa)\n",
    "execute_code(df, \"Whats for dinner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv('Titanic_train.csv')\n",
    "display(tt.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Draft 3.0 (Working, with UI & file upload (via ui) + refined exec check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim_S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def load_csv(file):\n",
    "    df = pd.read_csv(file.name)\n",
    "    return df, df.columns.to_list()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 1.0: LLM ------------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 20,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "chat_session = model.start_chat(history=[])\n",
    "\n",
    "def generate_and_run_code(df, question):\n",
    "    column_names = df.columns.to_list()\n",
    "    prompt = f\"\"\"You are an experienced data analayst who specialises writing python code to answer the questions.\n",
    "            The data set you will be analysing contains the following columns {column_names}\n",
    "            You are to respond with the python code that would answer the question {question}.\n",
    "            The code you provide is to be run a dataframe called df which already exists.\n",
    "\n",
    "            The quality of your answer will be judged by the following criteria;\n",
    "            - Your code output will run succesfully with the python eval function\n",
    "            - Your code will run in a single step, it will not create a variable that then needs printing\n",
    "            - Your output will be python code that can be run by another system immediatedly without error or adjustment\n",
    "            - You will NOT provide any theory or suggestions on how to answer the question\n",
    "            - If your output can not be passed straight to another system and run without error then that is a failure on your part\n",
    "            - You do NOT need to provide comments in your code.\n",
    "            - Your code will be as simple as possible to answer the question but not simpler\n",
    "            - You will output your code as a function i.e.\n",
    "            def cde(df):\n",
    "                out = >insert created code here<\n",
    "                return out\n",
    "            The code will be surounded between these symbols \n",
    "            # \n",
    "            \\n 'code'\n",
    "            #\n",
    "            \"\"\"\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    return extract_python_code(generated_code)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.0: Clean up -------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "def extract_python_code(code_str):\n",
    "    code_str = re.sub(r'```python|```', '', code_str)\n",
    "    code_str = re.sub(r'#.*', '', code_str)\n",
    "    try:\n",
    "        ast.parse(code_str)\n",
    "        return code_str.strip()\n",
    "    except SyntaxError:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.0: Guard rails ----------------------------------\n",
    "# ----- (qa code prior to execution) ---------------------------\n",
    "# --------------------------------------------------------------\n",
    "import ast\n",
    "def is_safe_function(func_code):\n",
    "    try:\n",
    "        tree = ast.parse(func_code)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Import) or isinstance(node, ast.ImportFrom):\n",
    "                return False  # Block all imports\n",
    "            if isinstance(node, ast.Call) and isinstance(node.func, ast.Name):\n",
    "                if node.func.id in {\"exec\", \"eval\", \"open\", \"os\", \"subprocess\"}:\n",
    "                    return False  # Block dangerous functions\n",
    "            if isinstance(node, ast.Attribute):\n",
    "                if node.attr in {\"__globals__\", \"__dict__\", \"__class__\"}:\n",
    "                    return False  # Block access to sensitive attributes\n",
    "        return True  # Code is safe\n",
    "    except Exception:\n",
    "        return False  # In case of parsing error, reject the function\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 3.0: Execution ------------------------------------\n",
    "# ----- (code execution, output formatting) --------------------\n",
    "# --------------------------------------------------------------\n",
    "def execute_code(csv_file, question):\n",
    "    df, column_names = load_csv(csv_file)\n",
    "    generated_code = generate_and_run_code(df, question)\n",
    "    if not generated_code:\n",
    "        return \"Failed to generate valid code.\"\n",
    "    # Extract only the 'cde' function from the generated code\n",
    "    try:\n",
    "        tree = ast.parse(generated_code)\n",
    "        function_code = None\n",
    "        for node in tree.body:\n",
    "            if isinstance(node, ast.FunctionDef) and node.name == \"cde\":\n",
    "                function_code = ast.unparse(node)\n",
    "                break\n",
    "        if function_code is None:\n",
    "            return \"No function 'cde' found in the generated code.\"\n",
    "        if not is_safe_function(function_code):\n",
    "            return \"Function 'cde' is unsafe and cannot be executed.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error parsing code: {e}\"\n",
    "    safe_globals = {\"__builtins__\": {}}\n",
    "    safe_locals = {}\n",
    "    try:\n",
    "        exec(function_code, safe_globals, safe_locals)  # Only executes 'cde'\n",
    "    except Exception as e:\n",
    "        return f\"Execution error: {e}\"\n",
    "    if 'cde' in safe_locals and callable(safe_locals['cde']):\n",
    "        try:\n",
    "            result = safe_locals['cde'](df)\n",
    "\n",
    "            response = chat_session.send_message(f\"\"\"You are a super helpful agent who responds to enquires.\n",
    "                                    You have been provided with a question {question} and answer {result}.\n",
    "                                    Your task is to use the answer to respond to the question in an informative & helpful way\"\"\")\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Function execution error: {e}\"\n",
    "    return \"Execution completed, but function 'cde' did not execute properly.\"\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 5.0: ui -------------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "demo = gr.Interface(\n",
    "    fn=execute_code,\n",
    "    inputs=[gr.File(label=\"Upload CSV File\"), gr.Textbox(label=\"Enter your question\")],\n",
    "    outputs=gr.Textbox(label=\"Answer\"),\n",
    "    title=\"AI Data Analysis Assistant\",\n",
    "    description=\"Upload a CSV file and ask a question related to the dataset. The AI will generate, validate, and execute the necessary code.\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Draft 4.0 (Working, with UI & file upload (via ui) + refined exec check + output in markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def load_csv(file):\n",
    "    df = pd.read_csv(file.name)\n",
    "    return df, df.columns.to_list()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 1.0: LLM ------------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 20,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "chat_session = model.start_chat(history=[])\n",
    "\n",
    "def generate_and_run_code(df, question):\n",
    "    column_names = df.columns.to_list()\n",
    "    prompt = f\"\"\"You are an experienced data analayst who specialises writing python code to answer the questions.\n",
    "            The data set you will be analysing contains the following columns {column_names}\n",
    "            You are to respond with the python code that would answer the question {question}.\n",
    "            The code you provide is to be run a dataframe called df which already exists.\n",
    "\n",
    "            The quality of your answer will be judged by the following criteria;\n",
    "            - Your code output will run succesfully with the python eval function\n",
    "            - Your code will run in a single step, it will not create a variable that then needs printing\n",
    "            - Your output will be python code that can be run by another system immediatedly without error or adjustment\n",
    "            - You will NOT provide any theory or suggestions on how to answer the question\n",
    "            - If your output can not be passed straight to another system and run without error then that is a failure on your part\n",
    "            - You do NOT need to provide comments in your code.\n",
    "            - Your code will be as simple as possible to answer the question but not simpler\n",
    "            - You will output your code as a function i.e.\n",
    "            def cde(df):\n",
    "                out = >insert created code here<\n",
    "                return out\n",
    "            The code will be surounded between these symbols \n",
    "            # \n",
    "            \\n 'code'\n",
    "            #\n",
    "            \"\"\"\n",
    "    response = chat_session.send_message(prompt)\n",
    "    generated_code = response.text.strip()\n",
    "    return extract_python_code(generated_code)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.0: Clean up -------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "def extract_python_code(code_str):\n",
    "    code_str = re.sub(r'```python|```', '', code_str)\n",
    "    code_str = re.sub(r'#.*', '', code_str)\n",
    "    try:\n",
    "        ast.parse(code_str)\n",
    "        return code_str.strip()\n",
    "    except SyntaxError:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 2.0: Guard rails ----------------------------------\n",
    "# ----- (qa code prior to execution) ---------------------------\n",
    "# --------------------------------------------------------------\n",
    "import ast\n",
    "def is_safe_function(func_code):\n",
    "    try:\n",
    "        tree = ast.parse(func_code)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Import) or isinstance(node, ast.ImportFrom):\n",
    "                return False  # Block all imports\n",
    "            if isinstance(node, ast.Call) and isinstance(node.func, ast.Name):\n",
    "                if node.func.id in {\"exec\", \"eval\", \"open\", \"os\", \"subprocess\"}:\n",
    "                    return False  # Block dangerous functions\n",
    "            if isinstance(node, ast.Attribute):\n",
    "                if node.attr in {\"__globals__\", \"__dict__\", \"__class__\"}:\n",
    "                    return False  # Block access to sensitive attributes\n",
    "        return True  # Code is safe\n",
    "    except Exception:\n",
    "        return False  # In case of parsing error, reject the function\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 3.0: Execution ------------------------------------\n",
    "# ----- (code execution, output formatting) --------------------\n",
    "# --------------------------------------------------------------\n",
    "def execute_code(csv_file, question):\n",
    "    df, column_names = load_csv(csv_file)\n",
    "    generated_code = generate_and_run_code(df, question)\n",
    "    if not generated_code:\n",
    "        return \"Failed to generate valid code.\"\n",
    "    # Extract only the 'cde' function from the generated code\n",
    "    try:\n",
    "        tree = ast.parse(generated_code)\n",
    "        function_code = None\n",
    "        for node in tree.body:\n",
    "            if isinstance(node, ast.FunctionDef) and node.name == \"cde\":\n",
    "                function_code = ast.unparse(node)\n",
    "                break\n",
    "        if function_code is None:\n",
    "            return \"No function 'cde' found in the generated code.\"\n",
    "        if not is_safe_function(function_code):\n",
    "            return \"Function 'cde' is unsafe and cannot be executed.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error parsing code: {e}\"\n",
    "    safe_globals = {\"__builtins__\": {}}\n",
    "    safe_locals = {}\n",
    "    try:\n",
    "        exec(function_code, safe_globals, safe_locals)  # Only executes 'cde'\n",
    "    except Exception as e:\n",
    "        return f\"Execution error: {e}\"\n",
    "    if 'cde' in safe_locals and callable(safe_locals['cde']):\n",
    "        try:\n",
    "            result = safe_locals['cde'](df)\n",
    "\n",
    "            response = chat_session.send_message(f\"\"\"You are a super helpful agent who responds to enquires.\n",
    "                                    You have been provided with a question {question} and answer {result}.\n",
    "                                    Your task is to use the answer to respond to the question in an informative & helpful way.\n",
    "                                    Please provide output in a way it can be rendered using properly formatted Markdown text. \n",
    "                                    i.e. \n",
    "                                    - adding double newlines (\\n\\n) between paragraphs\n",
    "                                    - wrapping headings & key text in side ** \"\"\")\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Function execution error: {e}\"\n",
    "    return \"Execution completed, but function 'cde' did not execute properly.\"\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ----- Part 5.0: ui -------------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "import gradio as gr\n",
    "demo = gr.Interface(\n",
    "    fn=execute_code,\n",
    "    inputs=[gr.File(label=\"Upload CSV File\"), gr.Textbox(label=\"Enter your question\")],\n",
    "    outputs=gr.Markdown(label=\"Answer\"),  # Changed to gr.Markdown\n",
    "    title=\"AI Data Analysis Assistant\",\n",
    "    description=\"Upload a CSV file and ask a question related to the dataset to get helpful responses.\"\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
